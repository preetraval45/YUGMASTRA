"""
Vulnerability Scanner Agent
AI-powered vulnerability assessment and prioritization
"""

import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
from models.llm_manager import LLMManager
from services.rag_service import RAGService

logger = logging.getLogger(__name__)


class VulnerabilityScanner:
    """
    AI-powered vulnerability scanner

    Capabilities:
    - Code vulnerability analysis
    - Configuration security assessment
    - Dependency vulnerability checking
    - CVSS scoring and prioritization
    - Exploit prediction
    - Remediation recommendations
    """

    def __init__(self, llm_manager: LLMManager, rag_service: RAGService):
        self.llm = llm_manager
        self.rag = rag_service
        self.name = "VulnerabilityScanner"
        logger.info(f"Initialized {self.name}")

    async def scan_code(self, code: str, language: str) -> Dict[str, Any]:
        """Scan code for security vulnerabilities"""

        prompt = f"""
        Analyze the following {language} code for security vulnerabilities:

        ```{language}
        {code}
        ```

        Identify:
        1. Specific vulnerabilities (SQL Injection, XSS, CSRF, etc.)
        2. CWE classifications
        3. OWASP Top 10 mappings
        4. Severity levels (Critical/High/Medium/Low)
        5. Affected lines of code
        6. Exploitation scenarios
        7. Proof of concept (if applicable)
        8. Secure code fixes
        9. Best practices violated
        10. Additional security recommendations

        Format as structured vulnerability report.
        """

        context = await self.rag.get_relevant_context(f"{language} security vulnerabilities")

        analysis = await self.llm.generate(
            prompt=prompt,
            system="You are a security code reviewer identifying vulnerabilities.",
            context=context
        )

        return {
            "language": language,
            "code_length": len(code),
            "vulnerabilities": analysis,
            "timestamp": datetime.now().isoformat()
        }

    async def assess_configuration(self, config: Dict[str, Any], service_type: str) -> Dict[str, Any]:
        """Assess security configuration"""

        config_text = str(config)

        prompt = f"""
        Assess the security of this {service_type} configuration:

        {config_text}

        Evaluate:
        1. Security misconfigurations
        2. Hardening opportunities
        3. Compliance issues (CIS Benchmarks, NIST)
        4. Default credentials or weak settings
        5. Unnecessary services/features enabled
        6. Encryption settings
        7. Access control configurations
        8. Logging and monitoring settings
        9. Severity assessment for each issue
        10. Step-by-step remediation

        Provide secure configuration recommendations.
        """

        context = await self.rag.get_relevant_context(f"{service_type} security hardening")

        assessment = await self.llm.generate(
            prompt=prompt,
            system="You are a security engineer assessing system configurations.",
            context=context
        )

        return {
            "service_type": service_type,
            "assessment": assessment,
            "timestamp": datetime.now().isoformat()
        }

    async def check_dependencies(self, dependencies: List[Dict[str, str]]) -> Dict[str, Any]:
        """Check dependencies for known vulnerabilities"""

        deps_text = "\n".join([
            f"{d.get('name', 'unknown')}@{d.get('version', 'unknown')}"
            for d in dependencies
        ])

        prompt = f"""
        Analyze these software dependencies for known vulnerabilities:

        {deps_text}

        For each vulnerable dependency, provide:
        1. CVE IDs
        2. Vulnerability description
        3. CVSS score
        4. Severity level
        5. Attack vector
        6. Exploitability assessment
        7. Affected versions
        8. Fixed versions
        9. Workarounds (if no fix available)
        10. Upgrade priority

        Prioritize by risk level.
        """

        context = await self.rag.get_relevant_context("CVE vulnerability database")

        analysis = await self.llm.generate(
            prompt=prompt,
            system="You are a vulnerability analyst checking software dependencies.",
            context=context
        )

        return {
            "dependencies_count": len(dependencies),
            "vulnerabilities": analysis,
            "timestamp": datetime.now().isoformat()
        }

    async def calculate_cvss(self, vulnerability_details: str) -> Dict[str, Any]:
        """Calculate CVSS score for a vulnerability"""

        prompt = f"""
        Calculate CVSS v3.1 score for this vulnerability:

        {vulnerability_details}

        Provide:
        1. Base Score (0-10)
        2. Attack Vector (Network/Adjacent/Local/Physical)
        3. Attack Complexity (Low/High)
        4. Privileges Required (None/Low/High)
        5. User Interaction (None/Required)
        6. Scope (Unchanged/Changed)
        7. Confidentiality Impact (None/Low/High)
        8. Integrity Impact (None/Low/High)
        9. Availability Impact (None/Low/High)
        10. CVSS Vector String
        11. Severity Rating (Critical/High/Medium/Low)
        12. Detailed justification for each metric

        Use official CVSS v3.1 methodology.
        """

        cvss = await self.llm.generate(
            prompt=prompt,
            system="You are a CVSS scoring expert using CVSS v3.1 methodology."
        )

        return {
            "vulnerability": vulnerability_details,
            "cvss_analysis": cvss,
            "timestamp": datetime.now().isoformat()
        }

    async def predict_exploitability(self, cve_id: str, details: str) -> Dict[str, Any]:
        """Predict likelihood of exploitation"""

        prompt = f"""
        Predict the exploitability of {cve_id}:

        Details: {details}

        Assess:
        1. Exploit likelihood (Very High/High/Medium/Low/Very Low)
        2. Public exploit availability
        3. Exploit complexity
        4. Required attacker skill level
        5. Time to weaponization
        6. Detection difficulty
        7. Known exploitation in the wild
        8. Target attractiveness
        9. Remediation urgency
        10. Risk score (0-100)

        Consider EPSS (Exploit Prediction Scoring System) factors.
        """

        context = await self.rag.get_relevant_context(f"{cve_id} exploit")

        prediction = await self.llm.generate(
            prompt=prompt,
            system="You are an exploit analyst predicting vulnerability exploitation likelihood.",
            context=context
        )

        return {
            "cve_id": cve_id,
            "exploitability": prediction,
            "timestamp": datetime.now().isoformat()
        }

    async def generate_remediation_plan(self,
                                        vulnerabilities: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate comprehensive remediation plan"""

        vulns_text = "\n".join([
            f"Vulnerability {i+1}: {v.get('description', str(v))}"
            for i, v in enumerate(vulnerabilities)
        ])

        prompt = f"""
        Create a comprehensive remediation plan for these vulnerabilities:

        {vulns_text}

        Plan should include:
        1. Prioritization strategy
        2. Quick wins (easy fixes with high impact)
        3. Phased remediation approach
        4. Resource requirements
        5. Timeline estimates
        6. Temporary mitigations
        7. Verification procedures
        8. Rollback plans
        9. Communication plan
        10. Success metrics

        Order by risk-based priority.
        """

        plan = await self.llm.generate(
            prompt=prompt,
            system="You are a security architect creating vulnerability remediation plans."
        )

        return {
            "vulnerabilities_count": len(vulnerabilities),
            "remediation_plan": plan,
            "timestamp": datetime.now().isoformat()
        }

    async def assess_attack_surface(self, system_info: Dict[str, Any]) -> Dict[str, Any]:
        """Assess attack surface of a system"""

        system_text = str(system_info)

        prompt = f"""
        Assess the attack surface of this system:

        {system_text}

        Analyze:
        1. Exposed services and ports
        2. Network accessibility
        3. Authentication mechanisms
        4. API endpoints
        5. Third-party integrations
        6. Data flows
        7. Trust boundaries
        8. High-risk components
        9. Attack vectors
        10. Surface reduction recommendations

        Provide attack surface map and reduction strategy.
        """

        assessment = await self.llm.generate(
            prompt=prompt,
            system="You are a penetration tester assessing attack surfaces."
        )

        return {
            "system_info": system_info,
            "attack_surface": assessment,
            "timestamp": datetime.now().isoformat()
        }

    async def generate_security_report(self,
                                       scan_results: Dict[str, Any]) -> Dict[str, Any]:
        """Generate comprehensive security assessment report"""

        results_text = str(scan_results)

        prompt = f"""
        Generate a comprehensive security assessment report:

        Scan Results:
        {results_text}

        Report should include:
        1. Executive Summary
        2. Methodology
        3. Scope
        4. Key Findings
        5. Vulnerability Statistics
        6. Critical Issues
        7. Risk Assessment
        8. Compliance Status
        9. Remediation Priorities
        10. Recommendations
        11. Appendix (Technical Details)

        Format as professional security assessment report.
        """

        report = await self.llm.generate(
            prompt=prompt,
            system="You are a senior security consultant writing assessment reports."
        )

        return {
            "report": report,
            "timestamp": datetime.now().isoformat()
        }
