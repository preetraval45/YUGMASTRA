# YUGMASTRA AI Engine - FREE Models Only Configuration

# ==================== FREE LLM Providers ====================

# Ollama (Local FREE LLM - RECOMMENDED)
# Install: https://ollama.ai/download
# Run: ollama pull llama3 && ollama serve
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# HuggingFace (FREE Inference API - Optional)
# Get free token: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=

# ==================== PAID Providers (LEAVE EMPTY - NOT REQUIRED) ====================
# These are optional and NOT needed for the platform to work
OPENAI_API_KEY=
ANTHROPIC_API_KEY=

# ==================== Database Configuration ====================

# PostgreSQL
DATABASE_URL=postgresql://yugmastra:yugmastra_dev_password@postgres:5432/yugmastra

# Redis (optional, for caching)
REDIS_URL=redis://redis:6379/0

# Neo4j (optional, uses NetworkX fallback if unavailable)
NEO4J_URL=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=yugmastra

# ==================== AI Model Settings ====================

# Model storage
MODEL_DIR=./models
DATA_DIR=./data
MODEL_CACHE_DIR=./models/cache

# Force FREE models only
USE_FREE_MODELS_ONLY=true

# Vector Store (all FREE)
CHROMA_PERSIST_DIR=./data/chroma
FAISS_INDEX_DIR=./data/faiss

# Device (auto-detected: cuda if available, otherwise cpu)
DEVICE=auto

# ==================== Feature Flags ====================

ENABLE_KNOWLEDGE_GRAPH=true
ENABLE_ZERO_DAY_DISCOVERY=true
ENABLE_SIEM_GENERATOR=true
ENABLE_RL_TRAINING=true

# ==================== Logging ====================

LOG_LEVEL=INFO
LOG_FILE=./logs/ai-engine.log
LOG_FORMAT=json

# ==================== API Configuration ====================

API_HOST=0.0.0.0
API_PORT=8001
API_WORKERS=4
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:200,http://localhost:19006
