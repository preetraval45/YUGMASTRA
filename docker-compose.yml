# YUGMÄ€STRA - Production-Ready Setup
# Optimized containers with health checks, monitoring, and proper networking

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: yugmastra-postgres
    environment:
      POSTGRES_DB: yugmastra
      POSTGRES_USER: yugmastra
      POSTGRES_PASSWORD: yugmastra_dev_password
      POSTGRES_MAX_CONNECTIONS: 200
      POSTGRES_SHARED_BUFFERS: 256MB
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups/postgres:/backups
    networks:
      - yugmastra-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U yugmastra -d yugmastra"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 512M

  # Redis Cache & Queue
  redis:
    image: redis:7-alpine
    container_name: yugmastra-redis
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - yugmastra-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M

  # Ollama - Local LLM Server
  ollama:
    image: ollama/ollama:latest
    container_name: yugmastra-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    networks:
      - yugmastra-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
    environment:
      OLLAMA_HOST: 0.0.0.0:11434
      OLLAMA_MODELS: /root/.ollama/models
      OLLAMA_KEEP_ALIVE: 5m

  # AI Engine - All AI Services Merged (Red Team + Blue Team + Evolution + LLM + RAG)
  ai-engine:
    build:
      context: ./services/ai-engine
      dockerfile: Dockerfile
      args:
        - PYTHON_VERSION=3.11
    container_name: yugmastra-ai-engine
    environment:
      DATABASE_URL: postgresql://yugmastra:yugmastra_dev_password@postgres:5432/yugmastra
      REDIS_URL: redis://redis:6379/0
      OLLAMA_URL: http://ollama:11434
      MODEL_DIR: /app/models
      DATA_DIR: /app/data
      LOG_LEVEL: INFO
      WORKERS: 4
      MAX_REQUESTS: 1000
      MAX_REQUESTS_JITTER: 100
      TIMEOUT: 300
      RATE_LIMIT_PER_MINUTE: 60
    networks:
      - yugmastra-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    volumes:
      - ./services/ai-engine:/app
      - ai_models:/app/models
      - ai_data:/app/data
      - ./logs/ai-engine:/app/logs
    ports:
      - "8001:8001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G

  # Web Application - Next.js Frontend + API Routes
  web:
    build:
      context: .
      dockerfile: ./apps/web/Dockerfile
      args:
        - NODE_VERSION=20
    container_name: yugmastra-web
    environment:
      DATABASE_URL: postgresql://yugmastra:yugmastra_dev_password@postgres:5432/yugmastra?schema=public
      REDIS_URL: redis://redis:6379/1
      JWT_SECRET: yugmastra-super-secret-jwt-key-change-in-production-2024
      NEXT_PUBLIC_API_URL: http://localhost:200/api
      NEXT_PUBLIC_WS_URL: http://localhost:200/ws
      AI_ENGINE_URL: http://ai-engine:8001
      NODE_ENV: production
      LOG_LEVEL: info
    networks:
      - yugmastra-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ai-engine:
        condition: service_healthy
    volumes:
      - ./logs/web:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 512M

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: yugmastra-nginx
    ports:
      - "200:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./logs/nginx:/var/log/nginx
    networks:
      - yugmastra-network
    depends_on:
      web:
        condition: service_healthy
      ai-engine:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ollama_models:
    driver: local
  ai_models:
    driver: local
  ai_data:
    driver: local

networks:
  yugmastra-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
